Observability vs Monitoring

Both provide tools tools to collect data, give insights, detect issues.

Monitoring :-
    Process of collecting, Analyzing and displaying predefined set of metrics, Which allows us to find out if something goes wrong

    But Monitorin does not tell us, what is wrong and how to remediate the problem.

Observability :-
    Observability enables us to actively debug, search for patterns, follow our microservices inputs and outputs and get insights into the behavior of our system.

    Observiability allows us to follow individual requests, transactions and events. Doscover and isolate performence bottlenecks and point us to the source of the problem.

    
While monitoring is very important for any type of system, observability is primarily critical for microservices architecture.


Three pillers of observability
1. Distributed logging
2.  Metrics
3. Distributed tracing



## 1.  Distributed logging :-
    Logging is one of the simplest way for developers to provide nsights into the current state of an application.

    A log line can represent an application's event like receiving a new request or an action like performing,a database query or starting a complex processing operation.It's also a way to record exceptions and errors in a method accompanied by the set of parameters that led to that issue. This information can be invaluable to debug and fix the issue and add enough tests to prevent such bugs in the future.


    Best Practices:-
    1. Centralized logging system

    In microservices architecture we can have thousands of instances of different microservices. It is not practicle to check each microservices, So one of the best thing to do is having centralized logging System. 

    1. Move all logs to central logging system, which is scalable
    2. Central logging system should parse and index those logs, to search by patterns or gorups
    
    2.  Predefined Structure or schema
    It also to have predefined structure or schema and same terminology accross the different events in microservices
    logline should be easy to read for humans as well as machines

    3.  Log level / Log severity
    Assigning a log level for each logline, depending on the system and framework we use
    Types of log level
    1.  TRACE
    2.  DEBUG
    3.  INFO
    4.  WARN
    5.  ERROR
    6.  FATAL

    4. Corelation Id
    5. Contextual information to logline
        Common Data points to add in Context of logs
        1. Service name
        2. Hostname / IP address
        3. User ID
        4. Timestamp
        Contextual Information
        1. Log Only necessary data
        2. Do not log
            - Sensitive data
            - PII (personally Identifiable Information)

## 2.  Metrics :-
    Metrics are measurable or accountable signals of software that help us monitor the system's health and performance.
    Metrics are regularly sampled, so we can see a continuous rogression which helps us monitor our system and detect anomalies when they occur and they usually come in numerical values. So we can easily quantify them and set alerts based on their direct or derived values because they are just numbers.

    Since metrics are numeric values, they are easiest to collect, export into dashboard
    1.  Regularly sampled data points
    2.  Numerical values
        - Counters
        - Distributions
        - Gauges
    3. Examples:
        - Requests /min
        - Errors /Hours
        - Latency distribution
        - Current CPU utilization
  
    <b>The 5 "Golden signals / mtrics" </b>
    Eventhough we can collect anything in the metrics, it is not good practice to collect every data from the system. 

    The 5 "golden signal / metrics" standard will provide the most information and the lease amount of noise
    The Five(golden) types of signals are sourced from "The Four golden Signals" (Google SRE book) and the USE method by Brendan Gregg

    1.  Traffic
    2.  Errors
    3.  Latency
    4.  Saturation
    5.  Utilization

    1. Traffic
        Amount of demand being placed on our system per unit of time

        Examples:
        - HTTP requests/sec
        - Queries/sec
        - Transactions/sec
        - Events received/sec
        - Events delivered/sec
        - incoming requests + outgoing requests/sec
    2.  Errors
        Error Rate and Error Types
        Examples:
        - Number of application exceptions
        - HTTP response status codes(4XX, 5XX)
        - Response exceeding latecy thresholds
        - Failed Events
        - Failed Delivery
        - Aborted transactions
        - Disk failures
    3.  Latency 
        Time it takes for a service to process a request
        Important considerations:
        - Latency distribution vs average
            The first important consideration is not to look just at the average latency, but always consider the full latency distribution.
        - Seperate successful operations from failed operations
    4.  Saturation
        How overload / full a service/resource is. Saturation is very important metrics in queue
    5.  Utilization
        HOw busy a resource is (0 - 100%)
        This typically applies to resources with limited capacity like CPU, memory, disk space and so on.

Final words:-
    The 5 golden aren't the only one we should collect. depending on the requirement we can collect other metrics as well. But they are the most common and give us the most value by tracking them


## 3.   Distributed Tracing
Distributed tracing is a method of tracking requests as they flow through the entire system. starts at the client's device all the way through our backend services and databases. As the request is being traced, we collect critical performance information about the time each part of the system is processing it.

Distributed tracing is not enough on its own to debug or troubleshoot the issue. but Distributed tracing helps to narrow down the faulty component and communication problem. once the problem is figured out we can use logs and metrics to debug further.
TODO
how it works?

Challenges with Distributed tracing

1.  Manual instrumnetation of code
2. cost
3.  Big traces problem



# Distributed Tracing Solutions
Distributed Tracing Instrumentation Frameworks
OpenTelemetry - OpenTelemetry is a is a collection of APIs, SDKs, and tools for instrumenting, collecting, and exporting metrics, logs, and traces. It is open-source and is available in many programming languages such as C++, #/.NET, Erlang/Elixir, Go, Java, JavaScript, PHP, Python, Ruby, Rust, and Swift.

OpenTelemetry is also a specification that describes the cross-language requirements and expectations for all OpenTelemetry implementations.

Distributed Tracing Backends
Jaeger - Open source, distributed tracing platform that is cloud-native, infinitely scalable, and 100% free. It enables the monitoring of distributed workflows, tracking down root causes for performance bottlenecks, and analyzing service dependencies.

Requies OpenTelemetry for instrumentation .

Zipkin - Another open-source distributed tracing system. Its data served to the UI is stored in memory or persistently within Apache Cassandra or Elasticsearch. Originally developed at Twitter in 2010 and based on Google's Dapper papers.

Supports a variety of official and community-created instrumentation frameworks.

Uptrace - Uptrace is an OpenTelemetry-based observability platform that helps you monitor, understand, and optimize distributed systems.

It is a commercial, cloud-based solution that supports a variety of features such as App Performance Monitoring, metrics collection and visualization, logs injection and analysis, and more.

    1. Path of a given request through several micrservices
    2. Time each microservices took to process it
    3. May include
     - Request headers
     - Response status code